{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic RAG Using CrewAI & LangChain\n",
        "We are going to see how agents can be involved in the RAG system to retrieve the most relevant information.\n",
        "\n"
      ],
      "metadata": {
        "id": "wCehIpnAl2S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title requirements\n",
        "!pip install --q crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29 sentence-transformers langchain-groq  langchain_huggingface"
      ],
      "metadata": {
        "id": "1zrm0uNomAd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Dependencies\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "from crewai import Agent, Task, Crew\n",
        "from crewai_tools import tool, PDFSearchTool\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "I1yxvzLBIevV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Environment Variable\n",
        "os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "UTwykI_JMZ0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Model Engine\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_base=\"https://api.groq.com/openai/v1\",\n",
        "    openai_api_key=os.environ['GROQ_API_KEY'],\n",
        "    model_name=\"llama3-8b-8192\",\n",
        "    temperature=0.1,\n",
        "    max_tokens=1000,\n",
        ")"
      ],
      "metadata": {
        "id": "qHlnl6xiM3_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "pdf_url = 'https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf'\n",
        "response = requests.get(pdf_url)\n",
        "\n",
        "with open('attenstion_is_all_you_need.pdf', 'wb') as file:\n",
        "    file.write(response.content)"
      ],
      "metadata": {
        "id": "05kQlRw_nvmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a RAG tool variable to pass our PDF\n"
      ],
      "metadata": {
        "id": "zX7fSWcUnPKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_tool = PDFSearchTool(pdf='attenstion_is_all_you_need.pdf',\n",
        "    config=dict(\n",
        "        llm=dict(\n",
        "            provider=\"groq\", # or google, openai, anthropic, llama2, ...\n",
        "            config=dict(\n",
        "                model=\"llama3-8b-8192\",\n",
        "                temperature = 0.5,\n",
        "                top_p = 0.9,\n",
        "                stream = True,\n",
        "            ),\n",
        "        ),\n",
        "        embedder=dict(\n",
        "            provider=\"huggingface\", # or openai, ollama, ...\n",
        "            config=dict(\n",
        "                model=\"BAAI/bge-small-en-v1.5\",\n",
        "                #task_type=\"retrieval_document\",\n",
        "                #title=\"Embeddings\",\n",
        "            ),\n",
        "        ),\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "JFRD_4bCNV5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(rag_tool.run(\"How did self-attention mechanism evolve in large language models?\"))"
      ],
      "metadata": {
        "id": "FBVBo9qbn0wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool - Tavily API Key"
      ],
      "metadata": {
        "id": "RSpFTW6wojtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the Tavily API key\n",
        "os.environ['TAVILY_API_KEY'] = userdata.get('TAVILY_API_KEY')\n",
        "web_search_tool = TavilySearchResults(k=3)"
      ],
      "metadata": {
        "id": "csD8Y4tuoXKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(web_search_tool.run(\"What is self-attention mechansim in large language models?\"))"
      ],
      "metadata": {
        "id": "U1_twO0Voyi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define a Tool**"
      ],
      "metadata": {
        "id": "dI9ePBdJsV3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tool\n",
        "@tool\n",
        "def router_tool(question):\n",
        "  \"\"\"Router Function\"\"\"\n",
        "  if \"self-attention\" in question:\n",
        "    return \"vectorstore\"\n",
        "  else:\n",
        "    return \"web_search\""
      ],
      "metadata": {
        "id": "6egtJRZFo3U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Agents to work with**\n"
      ],
      "metadata": {
        "id": "UCPR9jNLpcOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Router Agent\n",
        "\n",
        "Router_Agent = Agent(\n",
        "  role = \"Router\",\n",
        "  goal = \"Route user question to a vectorstore or websearch\",\n",
        "  backstory = (\n",
        "    \"You are an expert at routing a user question to a vectorstore or web search.\"\n",
        "    \"Use the vectorstore for questions on concept related to Retrieval-Augmented Generation.\"\n",
        "    \"You do not need to be stringent with the keywords in the question related to these topics. Otherwise, use web-search.\"\n",
        "  ),\n",
        "  verbose = True,\n",
        "  allow_delegation = False,\n",
        "  llm = llm\n",
        ")"
      ],
      "metadata": {
        "id": "sL_JYPHhphVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Retriever Agent\n",
        "Retriever_Agent = Agent(\n",
        "  role = \"Retriever\",\n",
        "  goal = \"Use the information retrieved from the vectorstore to answer the question\",\n",
        "  backstory=(\n",
        "    \"You are an assistant for question-answering tasks.\"\n",
        "    \"Use the information present in the retrieved context to answer the question.\"\n",
        "    \"You have to provide a clear concise answer.\"),\n",
        "  verbose = True,\n",
        "  allow_delegation = False,\n",
        "  llm = llm\n",
        ")"
      ],
      "metadata": {
        "id": "4meURJtbqEJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Grader Agent\n",
        "\n",
        "Grader_Agent = Agent(\n",
        "  role = \"Grader\",\n",
        "  goal = \"Filter out erroneous retrievals\",\n",
        "  backstory = (\n",
        "     \"You are a grader assessing relevance of a retrieved document to a user question.\"\n",
        "     \"If the document contains keywords related to the user question, grade it as relevant.\"\n",
        "     \"It does not need to be a stringent test.You have to make sure that the answer is relevant to the question.\"\n",
        "  ),\n",
        "  verbose = True,\n",
        "  allow_delegation = False,\n",
        "  llm = llm\n",
        ")"
      ],
      "metadata": {
        "id": "tofXyvWcqyAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Halluciantion Agent\n",
        "Halluciantion_Agent = Agent(\n",
        "  role = \"Hallucination Grader\",\n",
        "  goal = \"Filter out hallucination\",\n",
        "  backstory = (\n",
        "    \"You are a hallucination grader assessing whether an answer is grounded in / supported by a set of facts.\"\n",
        "    \"Make sure you meticulously review the answer and check if the response provided is in alignmnet with the question asked\"\n",
        "  ),\n",
        "  verbose = True,\n",
        "  allow_delegation = False,\n",
        "  llm = llm\n",
        ")"
      ],
      "metadata": {
        "id": "5ykrcB3VrTIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Answer Agent\n",
        "Answer_Agent = Agent(\n",
        "    role = \"Answerer\",\n",
        "    goal = \"Filter out hallucination from the answer.\",\n",
        "    backstory = (\n",
        "        \"You are a grader assessing whether an answer is useful to resolve a question.\"\n",
        "        \"Make sure you meticulously review the answer and check if it makes sense for the question asked\"\n",
        "        \"If the answer is relevant generate a clear and concise response.\"\n",
        "        \"If the answer gnerated is not relevant then perform a websearch using 'web_search_tool'\"\n",
        "    ),\n",
        "    verbose = True,\n",
        "    allow_delegation = False,\n",
        "    llm = llm\n",
        ")"
      ],
      "metadata": {
        "id": "AzoGABTrr1o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining Tasks**"
      ],
      "metadata": {
        "id": "j2pNC4k4scMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Router Task\n",
        "router_task = Task(\n",
        "    description=(\n",
        "    \"Analyse the keywords in the question {question}\"\n",
        "    \"Based on the keywords decide whether it is eligible for a vectorstore search or a web search.\"\n",
        "    \"Return a single word 'vectorstore' if it is eligible for vectorstore search.\"\n",
        "    \"Return a single word 'websearch' if it is eligible for web search.\"\n",
        "    \"Do not provide any other premable or explaination.\"\n",
        "    ),\n",
        "    expected_output=(\"Give a binary choice 'websearch' or 'vectorstore' based on the question\"\n",
        "    \"Do not provide any other premable or explaination.\"),\n",
        "    agent=Router_Agent,\n",
        "    tools=[router_tool],\n",
        ")"
      ],
      "metadata": {
        "id": "kFHA9zK1uu04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Retriever Task\n",
        "retriever_task = Task(\n",
        "    description = (\n",
        "      \"Based on the response from the router task extract information for the question {question} with the help of the respective tool.\"\n",
        "      \"Use the web_serach_tool to retrieve information from the web in case the router task output is 'websearch'.\"\n",
        "      \"Use the rag_tool to retrieve information from the vectorstore in case the router task output is 'vectorstore'.\"),\n",
        "    expected_output = (\n",
        "      \"You should analyse the output of the 'router_task'\"\n",
        "      \"If the response is 'websearch' then use the web_search_tool to retrieve information from the web.\"\n",
        "      \"If the response is 'vectorstore' then use the rag_tool to retrieve information from the vectorstore.\"\n",
        "      \"Return a claer and consise text as response.\"),\n",
        "    agent = Retriever_Agent,\n",
        "    context = [router_task],\n",
        "    #tools = [retriver_tool]\n",
        ")"
      ],
      "metadata": {
        "id": "StcqgbcItNEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Grader Task\n",
        "grader_task = Task(\n",
        "    description=(\"Based on the response from the retriever task for the quetion {question} evaluate whether the retrieved content is relevant to the question.\"\n",
        "    ),\n",
        "    expected_output=(\"Binary score 'yes' or 'no' score to indicate whether the document is relevant to the question\"\n",
        "    \"You must answer 'yes' if the response from the 'retriever_task' is in alignment with the question asked.\"\n",
        "    \"You must answer 'no' if the response from the 'retriever_task' is not in alignment with the question asked.\"\n",
        "    \"Do not provide any preamble or explanations except for 'yes' or 'no'.\"),\n",
        "    agent=Grader_Agent,\n",
        "    context=[retriever_task],\n",
        ")"
      ],
      "metadata": {
        "id": "7VUIVHKzvSr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hallucination Task\n",
        "hallucination_task = Task(\n",
        "    description=(\"Based on the response from the grader task for the quetion {question} evaluate whether the answer is grounded in / supported by a set of facts.\"),\n",
        "    expected_output=(\"Binary score 'yes' or 'no' score to indicate whether the answer is sync with the question asked\"\n",
        "    \"Respond 'yes' if the answer is in useful and contains fact about the question asked.\"\n",
        "    \"Respond 'no' if the answer is not useful and does not contains fact about the question asked.\"\n",
        "    \"Do not provide any preamble or explanations except for 'yes' or 'no'.\"),\n",
        "    agent=Halluciantion_Agent,\n",
        "    context=[grader_task],\n",
        ")\n"
      ],
      "metadata": {
        "id": "y-pHyuKQvjhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Answer Task\n",
        "answer_task = Task(\n",
        "    description=(\"Based on the response from the hallucination task for the quetion {question} evaluate whether the answer is useful to resolve the question.\"\n",
        "    \"If the answer is 'yes' return a clear and concise answer.\"\n",
        "    \"If the answer is 'no' then perform a 'websearch' and return the response\"),\n",
        "    expected_output=(\"Return a clear and concise response if the response from 'hallucination_task' is 'yes'.\"\n",
        "    \"Perform a web search using 'web_search_tool' and return ta clear and concise response only if the response from 'hallucination_task' is 'no'.\"\n",
        "    \"Otherwise respond as 'Sorry! unable to find a valid response'.\"),\n",
        "    context=[hallucination_task],\n",
        "    agent=Answer_Agent,\n",
        "    #tools=[answer_grader_tool],\n",
        ")"
      ],
      "metadata": {
        "id": "NaxFS0eMvsXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define a flow for the use case**"
      ],
      "metadata": {
        "id": "Q9o--BTmv_mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Crew flow\n",
        "rag_crew = Crew(\n",
        "    agents = [Router_Agent, Retriever_Agent, Grader_Agent, Halluciantion_Agent, Answer_Agent],\n",
        "    tasks = [router_task, retriever_task, grader_task, hallucination_task, answer_task],\n",
        "    verbose = True\n",
        ")"
      ],
      "metadata": {
        "id": "loEr6wz6wHzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ask any query**"
      ],
      "metadata": {
        "id": "trPNwWYvwxvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs ={\"question\":\"How does self-attention mechanism help large language models?\"}"
      ],
      "metadata": {
        "id": "d6s7pJ4Gw0jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Kick off the agent pipeline**"
      ],
      "metadata": {
        "id": "3siwFAVpw5fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = rag_crew.kickoff(inputs)"
      ],
      "metadata": {
        "id": "XVJZ4Itzw7F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Obtain the final response**"
      ],
      "metadata": {
        "id": "jIYHy59UxKWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result)"
      ],
      "metadata": {
        "id": "HxmIYKvNxJ9M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}